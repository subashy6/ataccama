# -------------------------------- SPARK CONFIGURATION ----------------------------------------------------------
# All properties starting with spark. are passed to Spark. 
# The required properties are:
# spark.master - must be set to yarn; other modes are not supported
# spark.io.compression.codec - must be set to lz4
# 
# You can set additional spark.<custom> properties here. 

#----------------- ATACCAMA CONFIGURATION ----------------------------
spark.master=yarn
spark.submit.deployMode=client

spark.sql.catalogImplementation=hive
#spark.sql.hive.metastore.version=1.2.1
#spark.sql.hive.metastore.jars=builtin

# Hive libraries for Cloudera
#spark.sql.hive.metastore.jars=/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/opt/cloudera/parcels/CDH/lib/hive/lib/*

# Hive libraries for Hortonworks
#spark.sql.hive.metastore.jars=/usr/hdp/current/spark2-client/jars/*

#spark.yarn.historyServer.address=http://spark-history-server.com:18081

# Turn on Spark Warehouse Connector for Hive 3
#spark.ataccama.hive.version3=true

# Spark RDD partition size used in Spark RDD Reader step when heuristic is enabled
# Specified in megabytes, default is 120mb
#spark.ata.RDDRepartitionStep.partitionSize=120

spark.eventLog.enabled=true
# Default location for Cloudera
#spark.eventLog.dir=hdfs:///user/spark/spark2ApplicationHistory
# Default location for Hortonworks
#spark.eventLog.dir=hdfs:///spark2-history

spark.io.compression.codec=lz4

#---------------- Additional properties ----------------------------------



# Max Attempts may be used for debugging.
#spark.yarn.maxAppAttempts=1
#spark.yarn.queue=default


#------------------ Performance Optimization ----------------------------
spark.shuffle.service.enabled=true
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.maxExecutors=100
spark.dynamicAllocation.minExecutors=2

#spark.executor.instances=4

spark.executor.memory=4g
#spark.executor.cores=2

