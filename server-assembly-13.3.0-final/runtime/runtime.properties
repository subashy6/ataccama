#fileSystem.workFolders=
# comma separated list of folders where temporary files are allocated

#double.scale=10
# maximal number of decimal places of FLOAT data type

#engine.trimStringValues=true
# column values of type STRING are trimmed 

### Memory Manager ###
#
# couple of parameters customizing the memory manager behavior
#
#memoryManager.enabled=true
# enables memory manager
#
#memoryManager.memorySize=64M
# size of memory reserved for memory manager
#
#memoryManager.optimizePeriod=30
# memory optimimization frequency (in seconds)
#
#memoryManager.debug.enabled=true
# turn on/off debugging posibilities (console messages, ...)
#
#memoryManager.debug.fullDelay=200
# how long should be the delayed after caches are full - used only for development debuging
#
###

### Sorting ###
#
# used in many algorithms which need sorting of data (esp. UnifyEngine, Profiling and statistics alg.)
#
#sorter.inMemory=
# number of items sorted in memory (recommended 1000-100000 depending on item size and available memory)
#
#sorter.workFiles=
# max. number of temporary working files used for mergesort on disc (recommended 10-20)
#
#sorter.closeChunks=false
# specifies if the working file should be closed after writing
# of sorted chunk in stage of merging.
# when false, all working files may be opened at one time
# when true, only one working file will be opened at one time
#
###

### Grouping ###
#
# used in many algorithms which need grouping data (esp. UnifyEngine, Join, SimpleGroupClassifier, Profiling and statistics alg.)
#
# NOTE: for Unification step context, you can specialize parameters by prefix "unify.", e.g. unify.keyGrouper.compressLevel=2 
#
#keyGrouper.inMemory=10000
# number of items stored in memory
#
#keyGrouper.split=10
# the grouper splits data into this number of buckets
# number of temporary files needed for grouping is double of this
# this number should not be too low (min. 2) but neither too high (recommended 10-20, max. 50)
#
#keyGrouper.estimateGroupSize=10000
# estimated size of group which will be sorted
# the number should be near to sorter.inMemory parameter to eliminate mergesort on disc
# both parameters above affect number of (heavy-load) steps of grouping in which the whole data is transfered over disc
# aproximately: size of the grouped data <= keyGrouper.estimateGroupSize * (keyGrouper.split ^ number of steps)
#
#keyGrouper.compressLevel=0
# specifies level of compression during grouping.
# this parameter is more significant when huge data are grouped (full load, wide records).
# values: 0(default) means no compress
#        -1 default compress
#        1..9 compression level (1=max.speed, 9=max.compress)
#
#keyGrouper.bufferSize=1mb
# size of buffers which are used in stream writing/reading to/from buckets.
# the total memory consumption is about keyGrouper.bufferSize * (keyGrouper.split + 1)
#
#keyGrouper.parallelWrite=0
# when > 0, each bucket will be written in own thread, the value limits simultaneous i/o operation   

#asyncProcessor.queue=10
#asyncProcessor.chunk=1000
#

#flowGroup.maxMemGroup=1000
#flowGroup.maxMemTotal=100000
# some steps or its parts uses information about grouping (record descriptor) and assumes
# the groups are almost continuous. These parameters limits memory usage
#
###

# Hash Join strategy
#hashJoin.inMemory=10000
# number of right records kept in memory map before the lookup file is created
#hashJoin.parallel=0
# joining will be performed in parallel threads. 0 = not threaded, 1 = one thread
#hashJoin.chunkSize=1000
#hashJoin.queueSize=100
#hashJoin.lazyReopen=false
# after build of lookup file from right data, the file is closed and reopened on first left record
#hashJoin.compress=false
# compress lookup file for right data

### Memory mapped storages ###
#
# used in algorithms needing lookup files
#
#mbbStorage.maxBlock=256M
# max. size of memory block mapped to file as whole
#
#mbbStorage.increment=16M
# size of forward mapped block used for appending to file
#
###

### File repository ###
#
# used in UnifyEngine
#
#repository.indexBlock=4k
# size of index block
# has meaning only when new file repository is created or rebuilded by idxrebuid/shrink utility
# min=256, max=16k
#
#repository.dataBlock=64
# size of allocation unit of data file
# min=4, max=4k
#
#repository.compress=false
# records stored in data file will be compessed
#
#repository.indexCache=1600
# number of index block kept in memory
# doesn't meaning in case of full-load with repository.doNotUpdateIndexes=true
# min=100, max=20000
#
#repository.doNotUpdateIndexes=false
# indexes of repository will not be updated
# meaningful mainly in full-load or very big increment
# after processing the repository enforces index rebuild during next open
# index rebuild can be independently performed by utility idxrebuild
#
#repository.updateSleepInterval=5
# the repository is updated by asynchronous process
# parameter specifies number of seconds this process sleeps if it has no work to do
#
#repository.logCacheSize=10000
# all updates of repository are first stored into transaction log
# parameter specifies number of log items kept in memory to avoid disc reading during commit
#
#repository.maxLogFileSize=64M
# size limit of saved transaction log files (when saveLogs="true" is specified in UnifyEngine configuration)
# if last transaction log file reached this limit, the new one is established for storing of following transactions
#
#repository.dbTranSize=10000
# approx. number of rows inserted/updated into database repository in one transaction
# this parameter has meaning only for UnifyEngine step with database repository and directUpdate=true
# in this case, consistency of batch is not guaranted and transaction.coordinator parameter has minor role
# directUpdate may be significant for full-load of huge data when rollback space is limited 
#
#transaction.coordinator=implicit
# specify manner of transaction coordination
# values can be:
# implicit .... transactions are commited/rollbacked at the same time when last client fires commit/rollback (something like two-phase commit)
# explicit .... transactions are commited/rollbacked at the same time when whole dqc process is finished
# immediate ... each transaction is commited at time its client fires commit (can cause inconsistency)
#
###

### Profiling ###
# max.number of items kept in memory during reading and processing profiled data
#profiling.inMemoryTotal=1000000
# part of inMemoryTotal which is used for final sorting
#profiling.inMemorySortPercent=50
#profiling.inMemorySortWeight=5
#
# number of rows in one transaction during drill-through writing, 0=all rows in one transaction 
#profiling.commitSize=10000

### Unifying ###
#
#unify.verbose=2
# how much of messages will be send to log
# 0 ... mute
# 1 ... info about numbers of records processed in step (new/updated/reunify/deleted..)
# 2 ... + info about repository operations
# 3 ... + info about processing of operations (ExtendedUnify only)
# 4 ... + info about phases of unification process
#
#unionMap.inMemory=64M
# maximal size of long[] array used as record->groupid mapping during unioning. This parameter is
# critical for performance of union/hierarchical methods or UnifyExtended in super-grouping.
# The value should correspond to total number processed records.
# The memory consumption is 8*value bytes (for each union method occurrence).
#
#repository.bytesPerChar=1 (2 for Oracle)
# Estimated average number of bytes required for storing one char.
# 
#repository.dataMaxLen=4000
# Size of chunk of serialized record stored into one data column.
# The minimal value is 100.
# Default value may vary depending on database type (MSAccess:255, Oracle:4000/bytesPerChar).
# 
#repository.dataColumns=5
# Number of data columns. The last column is of type CLOB to save huge records overflow.
# The minimal value is 2.
# Default value may vary depending on database type.
#
#repository.ukeyMaxLen=500
# Maximal length of unification key stored into database repository.
# When the key exceeds this, it is converted to first ukeyMaxLen-32 characters followed
# by 32 hexadecimal numbers of md5 of rest. The keys are unchanged in file repository.
# The minimal value is 40.
# Default value may vary depending on database type (MSAccess:127, MySql:220).
#
#repository.pkMaxLen=repository.ukeyMaxLen/2
# Maximal length of primary key stored into database repository.
# The minimal value is 20.
#
#repository.binary=true
# Store record data in binary type columns if possible
#
#repository.minTranCommitSize=1000
# Minimal number of records in one db transaction
# Note: too big value may be inconvenient in case of concurrent online and batch processing, because it might cause a number of wasted restart
#
#repository.statementBatchSize=1000
# Number of rows in one sql statement batch (affects work table insertions and repository updating)
#
#repository.workTableCommitSize=10000
# Number of work table rows per one transaction (affects work table insertions), should be multiple of repository.statemenBatchSize
#

#unify.parallelSegment=false
# Use parallel threads for processing distinct data segments (defined by groups and when conditions)

#unify.parallelMatchers=0
# Use parallel threads for splitting candidate into client groups. This parameter specifies
# number of threads. 0=no parallelism.
# additional parameters for parallel matching:
#unify.parallelWorkers=5
#unify.parallelWorkQueue=10

#unify.iterationChunkSize=1000
# maximal client groups that can be completed at once, if maxIterations and number of real client groups exceeds this,
# next groups are created in more stages.
# example: when maxIterations=10000, 4500 real client groups will be created in five stages (4*1000+500). 

#unify.maxRecordsInMemory=10000
# maximal number of candidate records kept in memory during client grouping (in one iteration stage limited by iterationChunkSize).

#unify.pkChecker.enable=true
#unify.pkChecker.inMemory=10000
# controls primary key checking on input

# Custom statements for database repository (for classic unification)
#[<stepId>.]repositoryCommandsFile=<file>.xml

# Custom statements for database repository (for extended unification)
# if not specified, file repository.xml in working folder is assumed
#[<repName>.]extRepositoryCommandsFile=<file>.xml
###

#memoryLogger.interval=0
# when specified (and not zero), message about used memory will be sent into log during dqc-process
# specifies interval in seconds between each message

#tempStorage.memoryLimit=16M
# size of memory used in random access temporary storage
# data exceeding this limit will be written to disc

#sortableStore.inMemory=10000
# number of items stored in memory
# used only in DataSamplerAlgorithm, GroupSelectorEngine

#indexedStore.inMemory=1000
# number of items stored in memory
# used only in DataSamplerAlgorithm, RemapTool

#queueBatcher.size=25
# size of one chunk of records transferred between steps

### Incremental (parallel unification) ###
#
#incremental.maxConcurent=100000
# maximum of concurently processed incremental transactions
#
###

### Dictionary Lookup Identifier ###
#dli.components.matchingValueRealValueRatio=4
# number of bits for storing key of the real value. 
# Rest of the (int) value is reserved for key accessing matching value (i.e. all
# real values with the same matching value)
#
###

###
#addressDoctor.debugLog=<file>.xml
# file for debug information about AddressDoctor setting and address parsing
###

###
#cpuAffinity.active=true
# Consider cpu affinity when checking license
###

###
#sql.monitorPerformance=false
# Enables debugging info about jdbc activity
###

###
#hbase.put.writeBufferSize=0
#Defines size of HBase client write buffer in MB. 0 means default value, -1 means do not use buffer at all
###

###
#hbase.scan.scanPrefetchSize=1000
#Number of rows to be read from region-server
###

###
#hbase.scan.blockCache=null
#Instructs region server to cache data in its block cache for particular scan operations
###

###
#canopyClustering.inMemoryCountIndexedTokens=10000
# Default number of token-records to be kept in memory.
###

###
#simpleDataSampler.maxRecordsKeptInMemory=1000
# Max records kept in memory while processing step Simple Data Sampler
###