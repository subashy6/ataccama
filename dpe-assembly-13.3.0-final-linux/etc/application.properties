# == Active profiles ==
 
# Available profiles (separate by commas, some are mutually exclusive):
#
# KEYCLOAK_DEV: temporary solution to enable authentication out of the box
# KEYCLOAK_LOCAL: alternative to KEYCLOAK_DEV setting the Keycloak to use local instance running at standard port
# NO_DPM_REGISTRATION: disables DPEs attempt to register to controlling DPM
# SPARK_DATABRICKS: enables launching spark jobs via Databricks cluster.
# SPARK_HADOOP: enables launching spark jobs via Hadoop cluster (available on linux platform only).
#
spring.profiles.active=KEYCLOAK_DEV

# == Authentication ==

# Keycloak settings (use as alternative to setting by the profiles)
#
#ataccama.authentication.keycloak.server-url=http://localhost:8029/auth
#ataccama.authentication.keycloak.realm=ataccamaone
#ataccama.authentication.keycloak.admin.client-id=dpe-admin-client
#ataccama.authentication.keycloak.admin.secret=dpe-admin-client-s3cret
#ataccama.authentication.keycloak.token.client-id=dpe-token-client
#ataccama.authentication.keycloak.token.secret=dpe-token-client-s3cret
#ataccama.authentication.keycloak.token.issuer=${ataccama.authentication.keycloak.server-url}/realms/${ataccama.authentication.keycloak.realm}

#ataccama.authentication.keycloak.admin.type=
#ataccama.authentication.keycloak.admin.key-store.file=
#ataccama.authentication.keycloak.admin.key-store.format=
#ataccama.authentication.keycloak.admin.key-store.password=
#ataccama.authentication.keycloak.admin.key-store.key-alias=
#ataccama.authentication.keycloak.admin.key-store.key-password=
#ataccama.authentication.keycloak.admin.token-expiration=

## == Overrides ==

# ONE Configuration Service client set-up
#ataccama.config-service.runtime=off
#ataccama.client.connection.configservice.host=localhost
#ataccama.client.connection.configservice.grpc.port=8511
#ataccama.authentication.internal.jwt.generator.key=<generated key>

# Basic gRPC server authorization settings
#ataccama.authentication.grpc.basic.enable=true
#ataccama.authentication.grpc.bearer.enable=true
#ataccama.authentication.grpc.internal.jwt.enable=true
#ataccama.authentication.grpc.mtls.enable=false

# Comma-separated list of environments this DPE belongs to.
#ataccama.one.dpe.environment=<environments>

#logging.level.root=INFO
logging.level.com.ataccama=INFO
#logging.level.com.ataccama.lib=INFO

#this could be set via LOG_PATH
#logging.file.path=${ataccama.path.log}

ataccama.logging.plainTextConsoleAppender = true
ataccama.logging.jsonConsoleAppender = false
ataccama.logging.plainTextFileAppender = false
ataccama.logging.jsonFileAppender = true

#plugins.path=./plugin
ataccama.one.dpe.drivers.path=${ataccama.path.root}/lib/jdbc

#ataccama.server.grpc.port = 8532
#ataccama.server.grpc.max-message-size=10MB

# HTTPS clients
#ataccama.client.http.tls.enabled=true
#ataccama.client.http.tls.trust-store=path to trust store #e.g. file:/path/to/truststore.p12
#ataccama.client.http.tls.trust-store-password=<password>

# gRPC server TLS config
#ataccama.server.grpc.tls.enabled=true|false
#ataccama.server.grpc.tls.cert-chain=path to certificate (public key) #e.g classpath:server.crt
#ataccama.server.grpc.tls.private-key=path to private key e.g. classpath:server.key
#ataccama.server.grpc.tls.trust-cert-collection=path to public certificate of trusted authority e.g. classpath:rootCA.crt
#ataccama.server.grpc.tls.mTls=NONE|OPTIONAL|REQUIRED
#ataccama.server.grpc.tls.trust-all=for mTLS to trust all tls connections
#ataccama.server.grpc.tls.hostname=dn name of generated server certificate (if it could not be resolved)
#ataccama.server.grpc.tls.key-store=path to keystore (higher priority then cert-chain and private-key)
#ataccama.server.grpc.tls.key-store-type=PKCS12|JCEKS (if not set, it will be detected)
#ataccama.server.grpc.tls.key-store-password=password used to keystore encryption
#ataccama.server.grpc.tls.key-alias=particular item in keystore (if not set it will be autodetected)
#ataccama.server.grpc.tls.key-password=password used to encrypt keys in keystore (if alias is not set, it must be same for all items in keystore)

ataccama.one.dpe.service.persistence.location=${ataccama.path.storage}
# Accepts two values - 'EMBEDDED' - use default embedded database for persistence or 'CUSTOM' - specify your own datasource via spring.
#ataccama.one.dpe.service.persistence.datasource-type=EMBEDDED

# Specify custom datasource if datasource type is set to 'CUSTOM'
#ataccama.one.dpe.service.persistence.driver-class-name=org.h2.Driver
#ataccama.one.dpe.service.persistence.url=jdbc:h2:mem:test
#ataccama.one.dpe.service.persistence.username=dpe
#ataccama.one.dpe.service.persistence.password=dpe

#In milliseconds
#ataccama.one.dpe.service.dpm.check-connection-interval=5000

# Global gRPC client config
#ataccama.client.grpc.properties.max-message-size=4MB

# Global gRPC client TLS/mTLS config
#ataccama.client.grpc.tls.enabled=true ## false by default
#ataccama.client.grpc.tls.mtls=true ## false by default
#ataccama.client.grpc.tls.trust-all ## for mTLS to trust all TLS connections
#ataccama.client.grpc.tls.cert-chain=file:path/to/cert/chain.crt ## empty by default
#ataccama.client.grpc.tls.private-key=file:path/to/private.key ## empty by default
#ataccama.client.grpc.tls.trust-cert-collection=file:path/to/trust/cert/chain.crt ## empty by default
#ataccama.client.grpc.tls.trust-store=file:path/to/trust/cert/trust-store.pfx ## empty by default
#ataccama.client.grpc.tls.trust-store-password=pswd ## empty by default
#ataccama.client.grpc.tls.trust-store-type=PKCS12|JCEKS ## empty by default


#ataccama.client.connection.dpm.name=dpm
#ataccama.client.connection.dpm.host=localhost
#ataccama.client.connection.dpm.grpc.port=8531
#ataccama.client.connection.dpm.grpc.tls.enabled=true
#ataccama.client.connection.dpm.grpc.tls.mTls=NONE|OPTIONAL|REQUIRED
#ataccama.client.connection.dpm.grpc.tls.trust-all=true
#ataccama.client.connection.dpm.grpc.tls.cert-chain=file:path/to/cert/chain.crt1
#ataccama.client.connection.dpm.grpc.tls.private-key=classpath:path/to/private.key1
#ataccama.client.connection.dpm.grpc.tls.trust-cert-collection=./path/to/trust/cert/chain.crt1
#ataccama.client.connection.dpm.grpc.tls.trust-store=file:path/to/trust/cert/trust-store.pfx
#ataccama.client.connection.dpm.grpc.tls.trust-store-password=pswd
#ataccama.client.connection.dpm.grpc.tls.trust-store-type=PKCS12|JCEKS


# Turns debug mode on (true) and off (false).
#ataccama.one.dpe.service.debug=false

#Override hostname in case DPE cannot be reached by machine hostname
#ataccama.one.dpe.service.hostname=localhost
#Override in case DPE cannot be reached by ataccama.server.grpc.port
#ataccama.one.dpe.service.port=8532

# HTTP server port
#server.port=8034

# Endpoints for monitoring
#management.endpoint.health.show-details=always
#management.endpoint.health.show-components=always
#management.endpoints.enabled-by-default=false
#management.endpoint.info.enabled=true
#management.endpoint.health.enabled=true
#management.endpoint.prometheus.enabled=true
#management.endpoints.web.exposure.include=health,info,prometheus
# Timing metrics to all spring endpoints (true by default)
#management.metrics.web.server.auto-time-requests=false

# If you want to restrict access to /actuator/health and /actuator/info (which are public by default), please uncomment and add them to the following line.
#ataccama.authentication.http.public-endpoint-restriction-filter=/actuator/prometheus
# Endpoints authentication (required to access /actuator/prometheus)
#ataccama.authentication.http.basic.enable=true

# Access control for endpoints
#ataccama.authentication.http.acl.endpoints.prometheus.endpoint-filter=/actuator/prometheus
#ataccama.authentication.http.acl.endpoints.prometheus.allowed-roles=ONE_PLATFORM_MONITORING

# Probes
#management.endpoint.health.probes.enabled=true
#management.endpoint.health.group.readiness.include=db,plugins
#management.endpoint.health.group.liveness.include=diskSpace,ping

# file system
#plugin.local-fs-datasource.ataccama.one.mounted.paths.default=../../filesystem

# Executor
# Relative to tmp/jobs/${jobId} from root dir of the assembly
plugin.executor-launch-model.ataccama.one.launch-type-properties.LOCAL.cpdelim=;
plugin.executor-launch-model.ataccama.one.launch-type-properties.LOCAL.cp.runtime=../../../lib/runtime/*;../../../lib/runtime/ext/*;../../../lib/jdbc/*;../../../lib/jdbc_ext/*

# Customization of job launch
#plugin.executor-launch-model.ataccama.one.launch-type-properties.LOCAL.exec=local/exec_local.sh

# Setup path to DQC licence if the licence is not present in home folder of the user or in runtime/license_keys
#plugin.executor-launch-model.ataccama.one.launch-type-properties.LOCAL.dqc.licenses=../../../lib/runtime/license_keys

#Setup JAVA_HOME (applicable if LOCAL.exec property is present). The runtime is compatible with JAVA 8 and higher.
#plugin.executor-launch-model.ataccama.one.launch-type-properties.LOCAL.env.JAVA_HOME=/usr/java/jdk1.8.0_65

# Setup any environment variable for local runs
#plugin.executor-launch-model.ataccama.one.launch-type-properties.LOCAL.env.ANY_ENVIRONMENT_VARIABLE=any environment variable value

# Comma-separated list of keys identifying the system properties which are allowed to be set through submitted jobs,
# thus making their values specific for the particular job.
# The job-specific system properties are passed to each spawned DQC runtime JVM associated with the identified launch type (LOCAL, SPARK, ...).
#plugin.executor-launch-model.ataccama.one.launch-type-properties.LOCAL.job-specific-system-properties.allowed-keys=

#plugin.executor.ataccama.one.job-expiration-interval=2h
# In milliseconds (spring does not support duration notation for @Scheduled currently). 1800000 milliseconds are 30 minutes.
#plugin.executor.ataccama.one.job-check-interval=1800000


# number of processes (or threads) that can be run concurrently
#plugin.executor.ataccama.one.max-parallel-jobs=5

# Shared file system
ataccama.one.object-storage.required-writable-buckets=executor
ataccama.one.object-storage.try-create=true
ataccama.one.object-storage.fail-fast=true

#ataccama.one.object-storage.storages[0].is-default=true
#ataccama.one.object-storage.storages[0].storage-id=minio
#ataccama.one.object-storage.storages[0].env=dev
#ataccama.one.object-storage.storages[0].storage-type=MINIO
#ataccama.one.object-storage.storages[0].connectionProperties.url=http://localhost:8091
#ataccama.one.object-storage.storages[0].connectionProperties.access-key=minio
#ataccama.one.object-storage.storages[0].connectionProperties.secret-key=minio-secret
#ataccama.one.object-storage.storages[0].connectionProperties.tmp-expiration=3600000

# DataConnect plugin config

# DataSource clients cache
# Maximum size of the cache (set to 0 to turn the caching off)
#plugin.data-connect.ataccama.one.caching.maximum-size=50
# Expiration time for the entries in the cache
#plugin.data-connect.ataccama.one.caching.duration=450s
# Flag to turn on or off recording of the cache stats (useful for potential performance monitoring)
#plugin.data-connect.ataccama.one.caching.record-stats=true
# The maximum number of threads available dedicated to closing of the clients, once they are evicted 
#plugin.data-connect.ataccama.one.max-closing-threads=10
# How long will the underlying cache keep result of cached items for browsing
#plugin.data-connect.ataccama.one.caching.browse-items-lifetime=300s
# Maximum number of browse query results to keep per each DataSourceClient
#plugin.data-connect.ataccama.one.caching.maximum-browse-items-results=100

# JDBC Data Source plugin config

# JDBC Data Source plugin default connection config
# Structure of keys [plugin prefix].connections.[parameter]
# Allows to define default JDBC connection configuration for all drivers at once. Each property can be overridden by setting it separately for each plugin.
# poolingEnabled: boolean value (as understood by Boolean.parseBoolean) indicating whether connection pooling is applied or not; defaults to false if not set
# connectionTimeout: how long in milliseconds does the pool manager (or a data source, if pooling is disabled) let the client wait for retrieving
#                    a new connection before timeout exception is thrown; defaults to either 20000 (when not pooling) or 30000 (when pooling) if not set
# idleTimeout: how long in milliseconds can a connection sit idly in the pool (if enabled) before it is retired; defaults to 600000 if not set
# maxLifetime: how long in milliseconds can a connection live in the pool (if enabled; currently used one is not retired), should be several seconds lower than database-imposed limits; defaults to 1800000 if not set
# minimumIdle: minimum idle connections present in the pool (if enabled); defaults to maximumPoolSize if not set
# maximumPoolSize: maximum total amount of both idle and used connections that can be present in the pool (if enabled; further requests for a connection are blocked); defaults to 10 if not set

#plugin.jdbcdatasource.ataccama.one.connections.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.connections.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.connections.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.connections.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.connections.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.connections.maximum-pool-size = 5

# JDBC Data Source plugin drivers config
# Structure of keys [plugin prefix].driver.[driverId].[parameter]
# Connection timeout and pooling-related keys default to the respective plugin.jdbcdatasource.connections.* values.
# driver-id: unique identifier of driver. Recommended to have id of database.
# profiling-sample-limit: number of rows to be profiled in sampling mode
# name: Human readable name shown on FE
# connection-pattern: Hint to user how jdbc url looks like
# driver-class-path: classpath for the driver
# driver-class: mandatory if multiple drivers found in driver-class-path
# provider-class: customized implementation class of provider. If parameter is missing default provider will be used. It should have some limitation such as exception sorting, escaping.
# pooling-enabled: driver-specific value of plugin.jdbcdatasource.ataccama.one.connections.pooling-enabled
# connection-timeout: driver-specific value of plugin.jdbcdatasource.ataccama.one.connections.connection-timeout
# idle-timeout: driver-specific value of plugin.jdbcdatasource.ataccama.one.connections.idle-timeout
# max-lifetime: driver-specific value of plugin.jdbcdatasource.ataccama.one.connections.max-lifetime
# minimum-idle: driver-specific value of plugin.jdbcdatasource.ataccama.one.connections.minimum-idle
# maximum-pool-size: driver-specific value of plugin.jdbcdatasource.ataccama.one.connections.maximum-pool-size
# SQL Query patterns:
# -- full-select-query-pattern: pattern for query used for loading full data. Allowed placeholders: {columns}, {table}.
# -- preview-query-pattern: pattern for query used for loading preview. Allowed placeholders: {columns}, {table}, {previewLimit}. Optional parameter.
#                    Pattern SELECT {columns} FROM {table} will be used if database specific pattern is missing.
# -- row-count-query-pattern: pattern for query used for count the number of rows of a table. Allowed placeholder: {table}
# -- sampling-query-pattern: pattern for query used for getting a sample data from table. Allowed placeholders: {table}, {columns}, {limit}, {percentageLimit}.
#
# Custom driver properties (for the drivers which support them) are prefixed by plugin.jdbcdatasource.ataccama.one.driver.<driver-id>.properties.,
# for example (for custom.property of the <driver-id> driver):
# plugin.jdbcdatasource.ataccama.one.driver.<driver-id>.properties.custom.property=custom property value

#plugin.jdbcdatasource.ataccama.one.driver.oracle.name=Oracle
#plugin.jdbcdatasource.ataccama.one.driver.oracle.connection-pattern=jdbc:oracle:thin:@<hostname>:<port>:<sid>
#plugin.jdbcdatasource.ataccama.one.driver.oracle.driver-class-path = ojdbc*.jar
#plugin.jdbcdatasource.ataccama.one.driver.oracle.provider-class = com.ataccama.dpe.plugin.dataconnect.jdbc.provider.oracle.OracleDataSourceClientProvider
#plugin.jdbcdatasource.ataccama.one.driver.oracle.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.oracle.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.oracle.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.oracle.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.oracle.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.oracle.maximum-pool-size = 5
#plugin.jdbcdatasource.ataccama.one.driver.oracle.profiling-sample-limit = 100000
#plugin.jdbcdatasource.ataccama.one.driver.oracle.full-select-query-pattern = SELECT {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.oracle.preview-query-pattern = SELECT {columns} FROM {table} WHERE ROWNUM <= {previewLimit}
#plugin.jdbcdatasource.ataccama.one.driver.oracle.row-count-query-pattern = SELECT COUNT(*) FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.oracle.sampling-query-pattern = SELECT {columns} FROM {table} SAMPLE ({percentageLimit})
# Example of custom driver property (prefixed by plugin.jdbcdatasource.ataccama.one.driver.oracle.properties.):
#plugin.jdbcdatasource.ataccama.one.driver.oracle.properties.oracle.jdbc.defaultRowPrefetch=1000


#plugin.jdbcdatasource.ataccama.one.driver.postgresql.name=PostgreSQL
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.connection-pattern=jdbc:postgresql://<hostname>:<port>/<database>
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.driver-class-path = postgresql-*.jar
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.provider-class = com.ataccama.dpe.plugin.dataconnect.jdbc.provider.postgresql.PostgreSQLDataSourceClientProvider
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.maximum-pool-size = 5
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.profiling-sample-limit = 100000
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.full-select-query-pattern = SELECT {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.preview-query-pattern = SELECT {columns} FROM {table} LIMIT {previewLimit}
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.row-count-query-pattern = SELECT COUNT(*) FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.sampling-query-pattern = SELECT {columns} FROM {table} WHERE RANDOM() < {percentageLimit} limit {limit}
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.sampling-query-pattern =SELECT {columns} FROM {table} TABLESAMPLE BERNOULLI({percentageLimit}) -- for Postgresql version >=9.5
# This driver supports custom properties, which can be set through:
#plugin.jdbcdatasource.ataccama.one.driver.postgresql.properties.NAME_OF_THE_CUSTOM_PROPERTY=CUSTOM_PROPERTY_VALUE

#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.name=Amazon Aurora PostgreSQL
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.connection-pattern=jdbc:postgresql://<hostname>:<port>/<database>
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.driver-class-path = postgresql-*.jar
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.provider-class = com.ataccama.dpe.plugin.dataconnect.jdbc.provider.postgresql.PostgreSQLDataSourceClientProvider
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.maximum-pool-size = 5
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.full-select-query-pattern = SELECT {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.preview-query-pattern = SELECT {columns} FROM {table} LIMIT {previewLimit}
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.row-count-query-pattern = SELECT COUNT(*) FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.sampling-query-pattern = SELECT {columns} FROM {table} WHERE RANDOM() < {percentageLimit} limit {limit}
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.sampling-query-pattern =SELECT {columns} FROM {table} TABLESAMPLE BERNOULLI({percentageLimit}) -- for Postgresql version >=9.5
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.query-quotation-mark =\"
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.disallowed-indexes-table-types=SYNONYM
# This driver supports custom properties, which can be set through:
#plugin.jdbcdatasource.ataccama.one.driver.aurora-postgresql.properties.NAME_OF_THE_CUSTOM_PROPERTY=CUSTOM_PROPERTY_VALUE

#plugin.jdbcdatasource.ataccama.one.driver.mysql.name=MySQL
#plugin.jdbcdatasource.ataccama.one.driver.mysql.connection-pattern=jdbc:mysql://<hostname>:<port>/<database>
#plugin.jdbcdatasource.ataccama.one.driver.mysql.driver-class-path = mysql-connector-java-8*.jar
#plugin.jdbcdatasource.ataccama.one.driver.mysql.provider-class = com.ataccama.dpe.plugin.dataconnect.jdbc.provider.mysql.MySQLDataSourceClientProvider
#plugin.jdbcdatasource.ataccama.one.driver.mysql.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.mysql.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.mysql.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.mysql.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.mysql.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.mysql.maximum-pool-size = 5
#plugin.jdbcdatasource.ataccama.one.driver.mysql.profiling-sample-limit = 100000
#plugin.jdbcdatasource.ataccama.one.driver.mysql.full-select-query-pattern = SELECT {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.mysql.preview-query-pattern = SELECT {columns} FROM {table} LIMIT {previewLimit}
#plugin.jdbcdatasource.ataccama.one.driver.mysql.row-count-query-pattern = SELECT COUNT(*) FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.mysql.sampling-query-pattern = SELECT {columns} FROM {table} WHERE RAND() < {percentageLimit};

#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.name=Amazon Aurora MySQL
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.connection-pattern=jdbc:mysql://<hostname>:<port>/<database>
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.driver-class-path = mysql-connector-java-8*.jar
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.provider-class = com.ataccama.dpe.plugin.dataconnect.jdbc.provider.mysql.MySQLDataSourceClientProvider
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.maximum-pool-size = 5
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.full-select-query-pattern = SELECT {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.preview-query-pattern = SELECT {columns} FROM {table} LIMIT {previewLimit}
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.row-count-query-pattern = SELECT COUNT(*) FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.sampling-query-pattern = SELECT {columns} FROM {table} WHERE RAND() < {percentageLimit};
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.query-quotation-mark =`
#plugin.jdbcdatasource.ataccama.one.driver.aurora-mysql.disallowed-indexes-table-types=SYNONYM

#plugin.jdbcdatasource.ataccama.one.driver.mssql.name=MSSQL Server
#plugin.jdbcdatasource.ataccama.one.driver.mssql.connection-pattern=jdbc:sqlserver://<hostname>:<port>;databaseName=<database>
#plugin.jdbcdatasource.ataccama.one.driver.mssql.driver-class-path = mssql-jdbc*.jar
#plugin.jdbcdatasource.ataccama.one.driver.mssql.provider-class = com.ataccama.dpe.plugin.dataconnect.jdbc.provider.mssql.MSSQLDataSourceClientProvider
#plugin.jdbcdatasource.ataccama.one.driver.mssql.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.mssql.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.mssql.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.mssql.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.mssql.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.mssql.maximum-pool-size = 5
#plugin.jdbcdatasource.ataccama.one.driver.mssql.profiling-sample-limit = 100000
#plugin.jdbcdatasource.ataccama.one.driver.mssql.full-select-query-pattern = SELECT {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.mssql.preview-query-pattern = SELECT TOP {previewLimit} {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.mssql.row-count-query-pattern = SELECT COUNT(*) FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.mssql.sampling-query-pattern = SELECT {columns} FROM {table} TABLESAMPLE ({percentageLimit} PERCENT)
#plugin.jdbcdatasource.ataccama.one.driver.mssql.sampling-query-pattern = IF (SELECT TABLE_TYPE FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = '{simpleTable}' AND TABLE_SCHEMA = '{schema}') = 'BASE TABLE' \
EXEC('SELECT {columns} FROM {table} TABLESAMPLE ({percentageLimit}*100 PERCENT)') \
 ELSE SELECT {columns} FROM (select t1.*, RAND(CHECKSUM(NEWID())) as ____rnd from {table} as t1) as t1 where ____rnd < {percentageLimit}
#plugin.jdbcdatasource.ataccama.one.driver.mssql.disallowed-indexes-table-types=SYNONYM

# A configuration of the MSSQL driver configuration which does no take shared lock on the rows at the expense of
# permitting dirty reads. USE AT YOU OWN CAUTION when inconsistent and incomplete results are acceptable.
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.disabled=false
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.name=MSSQL Server with no locks
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.connection-pattern=jdbc:sqlserver://<hostname>:<port>;databaseName=<database>
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.driver-class-path = mssql-jdbc*.jar
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.provider-class = com.ataccama.dpe.plugin.dataconnect.jdbc.provider.mssql.MSSQLDataSourceClientProvider
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.maximum-pool-size = 5
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.profiling-sample-limit = 100000
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.full-select-query-pattern = SELECT {columns} FROM {table} WITH (NOLOCK)
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.preview-query-pattern = SELECT TOP {previewLimit} {columns} FROM {table} WITH (NOLOCK)
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.row-count-query-pattern = SELECT COUNT(*) FROM {table} WITH (NOLOCK)
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.sampling-query-pattern = SELECT {columns} FROM {table} TABLESAMPLE ({percentageLimit} PERCENT) WITH (NOLOCK)
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.sampling-query-pattern = IF (SELECT TABLE_TYPE FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = '{simpleTable}' AND TABLE_SCHEMA = '{schema}') = 'BASE TABLE' \
EXEC('SELECT {columns} FROM {table} TABLESAMPLE ({percentageLimit}*100 PERCENT) WITH (NOLOCK)') \
 ELSE SELECT {columns} FROM (select t1.*, RAND(CHECKSUM(NEWID())) as ____rnd from {table} as t1 WITH (NOLOCK)) as t1 where ____rnd < {percentageLimit}
#plugin.jdbcdatasource.ataccama.one.driver.mssql-no-locks.disallowed-indexes-table-types=SYNONYM

#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.name=Azure Synapse Analytics
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.connection-pattern=jdbc:sqlserver://<hostname>:<port>;databaseName=<database>
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.driver-class-path = mssql-jdbc*.jar
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.provider-class = com.ataccama.dpe.plugin.dataconnect.jdbc.provider.mssql.MSSQLDataSourceClientProvider
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.maximum-pool-size = 5
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.full-select-query-pattern = SELECT {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.preview-query-pattern = SELECT TOP {previewLimit} {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.row-count-query-pattern = SELECT COUNT(*) FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.sampling-query-pattern = SELECT {columns} FROM {table} TABLESAMPLE ({percentageLimit} PERCENT)
#plugin.jdbcdatasource.ataccama.one.driver.azure-synapse.disallowed-indexes-table-types=SYNONYM

#plugin.jdbcdatasource.ataccama.one.driver.h2.name=H2
#plugin.jdbcdatasource.ataccama.one.driver.h2.connection-pattern=jdbc:h2:tcp://<hostname>:<port>/<database>
#plugin.jdbcdatasource.ataccama.one.driver.h2.driver-class-path = h2*.jar
#plugin.jdbcdatasource.ataccama.one.driver.h2.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.h2.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.h2.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.h2.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.h2.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.h2.maximum-pool-size = 5
#plugin.jdbcdatasource.ataccama.one.driver.h2.profiling-sample-limit = 100000
#plugin.jdbcdatasource.ataccama.one.driver.h2.full-select-query-pattern = SELECT {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.h2.preview-query-pattern = SELECT {columns} FROM {table} LIMIT {previewLimit}
#plugin.jdbcdatasource.ataccama.one.driver.h2.row-count-query-pattern = SELECT COUNT(*) FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.h2.sampling-query-pattern = SELECT {columns} FROM {table} LIMIT {limit}

#plugin.jdbcdatasource.ataccama.one.driver.redshift.name=Amazon Redshift
#plugin.jdbcdatasource.ataccama.one.driver.redshift.connection-pattern=jdbc:redshift://<hostname>:<port>/<database>
#plugin.jdbcdatasource.ataccama.one.driver.redshift.driver-class-path = Redshift*.jar
#plugin.jdbcdatasource.ataccama.one.driver.redshift.provider-class = com.ataccama.dpe.plugin.dataconnect.jdbc.provider.redshift.RedshiftDataSourceClientProvider
#plugin.jdbcdatasource.ataccama.one.driver.redshift.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.redshift.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.redshift.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.redshift.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.redshift.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.redshift.maximum-pool-size = 5
#plugin.jdbcdatasource.ataccama.one.driver.redshift.full-select-query-pattern = SELECT {columns} FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.redshift.preview-query-pattern = SELECT {columns} FROM {table} LIMIT {previewLimit}
#plugin.jdbcdatasource.ataccama.one.driver.redshift.row-count-query-pattern = SELECT COUNT(*) FROM {table}
#plugin.jdbcdatasource.ataccama.one.driver.redshift.sampling-query-pattern = SELECT {columns} FROM {table} WHERE RANDOM() < {percentageLimit} limit {limit}
#plugin.jdbcdatasource.ataccama.one.driver.redshift.query-quotation-mark =\"
#plugin.jdbcdatasource.ataccama.one.driver.redshift.disallowed-indexes-table-types=SYNONYM
# This driver supports custom properties, which can be set through:
#plugin.jdbcdatasource.ataccama.one.driver.redshift.properties.NAME_OF_THE_CUSTOM_PROPERTY=CUSTOM_PROPERTY_VALUE

plugin.jdbcdatasource.ataccama.one.driver.snowflake.name=Snowflake
plugin.jdbcdatasource.ataccama.one.driver.snowflake.connection-pattern=jdbc:snowflake://<hostname>:<port>?db=<database>
plugin.jdbcdatasource.ataccama.one.driver.snowflake.driver-class-path = snowflake-*.jar
plugin.jdbcdatasource.ataccama.one.driver.snowflake.provider-class = com.ataccama.dpe.plugin.dataconnect.jdbc.provider.snowflake.SnowflakeDataSourceClientProvider
#plugin.jdbcdatasource.ataccama.one.driver.snowflake.pooling-enabled = true
#plugin.jdbcdatasource.ataccama.one.driver.snowflake.connection-timeout = 20000
#plugin.jdbcdatasource.ataccama.one.driver.snowflake.idle-timeout = 300000
#plugin.jdbcdatasource.ataccama.one.driver.snowflake.max-lifetime = 900000
#plugin.jdbcdatasource.ataccama.one.driver.snowflake.minimum-idle = 1
#plugin.jdbcdatasource.ataccama.one.driver.snowflake.maximum-pool-size = 5
plugin.jdbcdatasource.ataccama.one.driver.snowflake.full-select-query-pattern = SELECT {columns} FROM {table}
plugin.jdbcdatasource.ataccama.one.driver.snowflake.preview-query-pattern = SELECT {columns} FROM {table} LIMIT {previewLimit}
plugin.jdbcdatasource.ataccama.one.driver.snowflake.row-count-query-pattern = SELECT COUNT(*) FROM {table}
plugin.jdbcdatasource.ataccama.one.driver.snowflake.sampling-query-pattern = SELECT {columns} FROM {table} WHERE RANDOM() < {percentageLimit}
plugin.jdbcdatasource.ataccama.one.driver.snowflake.query-quotation-mark =\"
plugin.jdbcdatasource.ataccama.one.driver.snowflake.disallowed-indexes-table-types=SYNONYM
# This driver supports custom properties, which can be set through:
#plugin.jdbcdatasource.ataccama.one.driver.snowflake.properties.NAME_OF_THE_CUSTOM_PROPERTY=CUSTOM_PROPERTY_VALUE

plugin.jdbcdatasource.ataccama.one.driver.bq.name=Big Query
plugin.jdbcdatasource.ataccama.one.driver.bq.connection-pattern=jdbc:bigquery://https://www.googleapis.com/bigquery/v2:443;ProjectId=<projectID>;OAuthType=<OAuthType>;
plugin.jdbcdatasource.ataccama.one.driver.bq.driver-class-path= GoogleBigQueryJDBC42.jar
plugin.jdbcdatasource.ataccama.one.driver.bq.additional-classpath-files= bigQueryLibs/*;
plugin.jdbcdatasource.ataccama.one.driver.bq.driver-class=com.simba.googlebigquery.jdbc42.Driver
plugin.jdbcdatasource.ataccama.one.driver.bq.pooling-enabled = false
plugin.jdbcdatasource.ataccama.one.driver.bq.connection-timeout = 20000
plugin.jdbcdatasource.ataccama.one.driver.bq.idle-timeout = 300000
plugin.jdbcdatasource.ataccama.one.driver.bq.max-lifetime = 900000
plugin.jdbcdatasource.ataccama.one.driver.bq.minimum-idle = 1
plugin.jdbcdatasource.ataccama.one.driver.bq.maximum-pool-size = 5
plugin.jdbcdatasource.ataccama.one.driver.bq.profiling-sample-limit = 100000
plugin.jdbcdatasource.ataccama.one.driver.bq.full-select-query-pattern = SELECT {columns} FROM {table}
plugin.jdbcdatasource.ataccama.one.driver.bq.preview-query-pattern = SELECT {columns} FROM {table}
plugin.jdbcdatasource.ataccama.one.driver.bq.row-count-query-pattern = SELECT COUNT(*) FROM {table}
plugin.jdbcdatasource.ataccama.one.driver.bq.sampling-query-pattern = SELECT {columns} FROM {table} WHERE RAND() < {percentageLimit};
plugin.jdbcdatasource.ataccama.one.driver.bq.query-quotation-mark =`
# This driver supports custom properties, which can be set through:
#plugin.jdbcdatasource.ataccama.one.driver.bq.properties.NAME_OF_THE_CUSTOM_PROPERTY=CUSTOM_PROPERTY_VALUE

# Metastore Data Source plugin config
# plugin.metastoredatasource.ataccama.one.cluster.[clusterId].[parameter]
# parameter name is optional, if not specified, name is clusterId
# parameter authentication can be KERBEROS, SIMPLE or TOKEN
#   * KERBEROS needs principal, keytab and impersonate
#   * SIMPLE does not need other parameters
#   * TOKEN does not need other parameters
#
# In case of Databricks cluster (TOKEN authentication) the cluster name MUST be the same as on Databricks
# (will be used to check the cluster state) and there are two other parameters:
#   * databricksUrl - URL to Databricks cluster, required, used to check whether cluster is running
#   * timeout - specifies time to retry to create connection in case cluster is not running, optional, default 15m

#plugin.metastoredatasource.ataccama.one.cluster.cloudera.name=
#plugin.metastoredatasource.ataccama.one.cluster.cloudera.url=
#plugin.metastoredatasource.ataccama.one.cluster.cloudera.driver-class=com.cloudera.hive.jdbc41.HS2Driver
#plugin.metastoredatasource.ataccama.one.cluster.cloudera.driver-class-path=${ataccama.path.root}/lib/runtime/jdbc/cloudera/*
#plugin.metastoredatasource.ataccama.one.cluster.cloudera.authentication=KERBEROS
#plugin.metastoredatasource.ataccama.one.cluster.cloudera.impersonate=true
#plugin.metastoredatasource.ataccama.one.cluster.cloudera.kerberos.principal=
#plugin.metastoredatasource.ataccama.one.cluster.cloudera.kerberos.keytab=
#plugin.metastoredatasource.ataccama.one.cluster.cloudera.profiling-sample-limit=100000

#plugin.metastoredatasource.ataccama.one.cluster.hortonworks.name=
#plugin.metastoredatasource.ataccama.one.cluster.hortonworks.url=
#plugin.metastoredatasource.ataccama.one.cluster.hortonworks.driver-class=org.apache.hive.jdbc.HiveDriver
#plugin.metastoredatasource.ataccama.one.cluster.hortonworks.driver-class-path=${ataccama.path.root}/lib/runtime/jdbc/hortonworks/*
#plugin.metastoredatasource.ataccama.one.cluster.hortonworks.authentication=KERBEROS
#plugin.metastoredatasource.ataccama.one.cluster.hortonworks.impersonate=true
#plugin.metastoredatasource.ataccama.one.cluster.hortonworks.kerberos.principal=
#plugin.metastoredatasource.ataccama.one.cluster.hortonworks.kerberos.keytab=
#plugin.metastoredatasource.ataccama.one.cluster.hortonworks.profiling-sample-limit=100000

#plugin.metastoredatasource.ataccama.one.cluster.databricks.name=
#plugin.metastoredatasource.ataccama.one.cluster.databricks.url=
#plugin.metastoredatasource.ataccama.one.cluster.databricks.databricksUrl=
#plugin.metastoredatasource.ataccama.one.cluster.databricks.timeout=15m
#plugin.metastoredatasource.ataccama.one.cluster.databricks.driver-class=com.simba.spark.jdbc4.Driver
#plugin.metastoredatasource.ataccama.one.cluster.databricks.driver-class-path=${ataccama.path.root}/lib/runtime/jdbc/databricks/*
#plugin.metastoredatasource.ataccama.one.cluster.databricks.authentication=TOKEN
#plugin.metastoredatasource.ataccama.one.cluster.databricks.profiling-sample-limit=100000


# Specification of constraint capabilities through properties
#
# Capabilities defined here allow to manually override capabilities of the DPE, which are usually derived from the installed plugins and active settings.
# They also provide means to set additional custom capabilities on top of that. Both are taken into account
# when matching the capabilities of the DPE with requirements of a request or a job submission received by the supervising DPM. For more information regarding the constraints,
# see README.md.
#
# The default format of constraining property value is a comma-separated list (with '"' as quoting character and '\' as escape character) of zero, one or
# more elementary string value capabilities.
# To use different capability type for the elements of the enumeration, start the property value with a type specifier enclosed in '[' and ']',
# e.g. to define an enumeration of pattern capabilities, start the property value with "[pattern]".
# When the first (or the only) string value capability has to begin with '[', specify first the string type explicitly by prefixing the whole property value with "[string]".
# The available type specifiers are: [string], [pattern], [long], [integer], [double], [float], [boolean]. Intervals, custom types and intervals of custom types are not currently supported.
# 
# Defining constraint capabilities as environmental properties is restricted to using the same elementary capability type for all elements of the enumeration.
# No nesting of enumerations is allowed and you can only use the primitive data types supported by the property value data type specifiers.
# When you need to express more complex constraints, consider extending the DPE with a plugin which simplifies the configuration of the constraint by doing it mostly programmatically and
# only exposing few simple capabilities to be configured manually. Even better, derive the constraints provided by the plugin completely from existing configuration options.
# As the last resort, you can write the constraints into the constraints.json file using the native constraint configuration format (see README.md), however the JSON files do not allow
# to include comments and they are not set to be supported by the dedicated remote configuration service any time soon.
#
#constraints.com.ataccama.dpp.environment=dev,test,prod
#constraints.com.ataccama.dpe.plugin.dataconnect.provider.type=FILESYSTEM,oracle,postgresql,mysql,mssql,h2,MDM,RDM,METASTORE_CLOUDERA,METASTORE_DATABRICKS,METASTORE_HORTONWORKS
#constraints.com.ataccama.dpe.plugin.executor.provider.type=DQC,DQM,METADATA-IMPORT
#constraints.com.ataccama.dpe.plugin.dataconnect.local.fs.datasource.mount=default
#constraints.com.ataccama.dpe.plugin.dataconnect.jdbc.connectionstring=[pattern]jdbc:oracle:.*,jdbc:postgresql:.*,jdbc:mysql:.*,jdbc:sqlserver:.*,jdbc:h2:.*

# We allow for all kinds of DQC data source URLs by default to not exclude DQC jobs using their own drivers.
# Feel free to tighten this constraint only to the registered data-connect or metastore drivers by commenting out the following
# constraint, or replacing it with your custom expression.
constraints.com.ataccama.dpe.plugin.dqc.datasource.url=[pattern].*

# Internal keystore configuration for decryption
#internal.encryption.keystore=<path/to/internal/keystore>
#internal.encryption.keystore.passwordFile=<path/to/internal/keystore/password-file>

# Properties keystore configuration for decryption
#properties.encryption.keystore=<path/to/properties/keystore>
#properties.encryption.keystore.passwordFile=<path/to/properties/keystore/password-file>

# graceful shutdown
#server.shutdown=graceful
#spring.lifecycle.timeout-per-shutdown-phase=30s
#plugin.executor.ataccama.one.server.shutdown.kill-jobs=true
#plugin.executor.ataccama.one.server.shutdown.wait-jobs-timeout=20s